'''
this code is run in Colab Google. So, this code takes folder from drive.
So if you run it in your pc you need not run the code to mount the drive.

And all the folder links are given with respect to the drive. So , if you want to run this code in your machine please 

change the path accrodingly.

For example :

if drive path is : '/content/gdrive/My Drive/train/fold_0/all/*.bmp'
then for your machine it will be  : 'YOUR_FOLDER_NAME/train/fold_0/all/*.bmp'

'''


from keras import applications
from keras import optimizers
from keras.applications.resnet50 import ResNet50
from keras.preprocessing import image
from keras.models import Model
from keras.layers import Dense, GlobalAveragePooling2D,Flatten,Dropout,Conv2D,MaxPooling2D
from keras.models import Sequential
from keras import backend as K
from keras.preprocessing.image import ImageDataGenerator
from PIL import Image
import glob
import numpy as np
import cv2 as cv
import matplotlib.pyplot as plt
plt.figure(figsize=(20,10))
from scipy.signal import convolve2d
def plti(im, h=8, **kwargs):
    """
    Helper function to plot an image.
    """
    y = im.shape[0]
    x = im.shape[1]
    w = (y/x) * h
    plt.figure(figsize=(w,h))
    plt.imshow(im, interpolation="none", **kwargs)
    plt.axis('off')

def edge(im_small):
  n=100
  sobel_x = np.c_[
      [-1,0,1],
      [-2,0,2],
      [-1,0,1]
  ]

  sobel_y = np.c_[
      [1,2,1],
      [0,0,0],
      [-1,-2,-1]
  ]

  ims = []
  for d in range(3):
      sx = convolve2d(im_small[:,:,d], sobel_x, mode="same", boundary="symm")
      sy = convolve2d(im_small[:,:,d], sobel_y, mode="same", boundary="symm")
      ims.append(np.sqrt(sx*sx + sy*sy))

  im_conv = np.stack(ims, axis=2).astype("uint8")
  return im_conv

def emboss(im_small):
  karnel = np.array(
  [
      [-1,-1,0],
      [-1,0,1],
      [0,1,1]
  ])
  ims = []
  for d in range(3):
      sx = convolve2d(im_small[:,:,d], karnel, mode="same", boundary="symm")
      ims.append(sx)
  im_conv = np.stack(ims, axis=2).astype("uint8")
  return im_conv

def channel_diff(im):
    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(20,20))

    for c, ax in zip(range(3), axs):
        tmp_im = np.zeros(im.shape, dtype="uint8")
        tmp_im[:,:,c] = im[:,:,c]
        ax.imshow(tmp_im)
        ax.set_axis_off()

def to_grayscale(im, weights = np.c_[0.2989, 0.5870, 0.1140]):
    """
    Transforms a colour image to a greyscale image by
    taking the mean of the RGB values, weighted
    by the matrix weights
    """
    tile = np.tile(weights, reps=(im.shape[0],im.shape[1],1))
    img= np.sum(tile * im, axis=2)
    return img
    #plti(img, cmap='Greys')
Images = []
labels = []
dim = 128
from scipy import ndimage
alpha = 1
#print(glob.glob('/content/gdrive/My Drive/train/fold_1/all/*.bmp'))
m=0
number = 1000
for filename in glob.glob('/content/gdrive/My Drive/train/fold_0/all/*.bmp'): #assuming gif
    m+=1
    if m>number:
      break
    im = image.load_img(filename, target_size=(dim, dim))
    im = image.img_to_array(im)
    im = np.array(im)
    
    filter_blurred_f = ndimage.gaussian_filter(im, 1)
    sharpened = im + alpha * (im - filter_blurred_f)
    
    #im = edge(im)
    #im = emboss(im)
    #im = edge(im)
    Images.append(im)
    labels.append(1)
    print(m)
m=0
for filename in glob.glob('/content/gdrive/My Drive/train/fold_1/all/*.bmp'): #assuming gif
    m+=1
    if m>10:
      break
    try:
      im = image.load_img(filename, target_size=(dim, dim))
      im = image.img_to_array(im)
      im = np.array(im)
      filter_blurred_f = ndimage.gaussian_filter(im, 1)
      sharpened = im + alpha * (im - filter_blurred_f)
      
      #im = edge(im)
      #im = emboss(im)
      #im = edge(im)
      Images.append(im)
      labels.append(1)
    except(OSError):
      print('error',m)
print(m)
m=0
for filename in glob.glob('/content/gdrive/My Drive/train/fold_2/all/*.bmp'): #assuming gif
    m+=1
    if m>number:
      break
    im = image.load_img(filename, target_size=(dim, dim))
    im = image.img_to_array(im)
    im = np.array(im)
    filter_blurred_f = ndimage.gaussian_filter(im, 1)
    sharpened = im + alpha * (im - filter_blurred_f)
    
    #im = edge(im)
    #im = emboss(im)
    #im = edge(im)
    Images.append(im)
    labels.append(1)
print(m)
m=0    
for filename in glob.glob('/content/gdrive/My Drive/train/fold_0/hem/*.bmp'): #assuming gif
    m+=1
    if m>number:
      break
    im = image.load_img(filename, target_size=(dim, dim))
    im = image.img_to_array(im)
    im = np.array(im)
    filter_blurred_f = ndimage.gaussian_filter(im, 1)
    sharpened = im + alpha * (im - filter_blurred_f)
    
    #im = edge(im)
    #im = emboss(im)
    #im = edge(im)
    Images.append(im)
    labels.append(0)
print(m)
m=0
for filename in glob.glob('/content/gdrive/My Drive/train/fold_1/hem/*.bmp'): #assuming gif
    m+=1
    if m>number:
      break
    im = image.load_img(filename, target_size=(dim, dim))
    im = image.img_to_array(im)
    im = np.array(im)
    filter_blurred_f = ndimage.gaussian_filter(im, 1)
    sharpened = im + alpha * (im - filter_blurred_f)
    
    #im = edge(im)
    #im = emboss(im)
    #im = edge(im)
    Images.append(im)
    labels.append(0)
print(m)
m=0
for filename in glob.glob('/content/gdrive/My Drive/train/fold_2/hem/*.bmp'): #assuming gif
    m+=1
    if m>number:
      break
    im = image.load_img(filename, target_size=(dim, dim))
    im = image.img_to_array(im)
    im = np.array(im)
    filter_blurred_f = ndimage.gaussian_filter(im, 1)
    sharpened = im + alpha * (im - filter_blurred_f)
   
    #im = edge(im)
    #im = emboss(im)
    #im = edge(im)
    Images.append(im)
    labels.append(0)
print(m)
print(len(Images), Images[0].shape)

i = Images[19]
plt.imshow( image.array_to_img(Images[40]) )
channel_diff(i)
#to_grayscale(i)
fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(50,50))
axs[0].imshow(emboss(i))
axs[1].imshow(edge(i))
axs[2].imshow(edge(emboss(i)), interpolation="none", cmap="Greys")
axs[3].imshow(emboss(edge(i)), interpolation="none", cmap="Greys")
              
i = Images[49]
#plt.imshow( image.array_to_img(Images[40]) )
channel_diff(i)
#to_grayscale(i)
fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(50,50))
axs[0].imshow(emboss(i))
axs[1].imshow(edge(i))
axs[2].imshow(edge(emboss(i)), interpolation="none", cmap="Greys")
axs[3].imshow(emboss(edge(i)), interpolation="none", cmap="Greys")
fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(50,50))
axs[0].imshow( to_grayscale(emboss(i)))
axs[1].imshow( to_grayscale(edge(i)))
axs[2].imshow( to_grayscale(edge(emboss(i))), interpolation="none", cmap="Greys")
axs[3].imshow( to_grayscale(emboss(edge(i))), interpolation="none", cmap="Greys")
from keras.applications.vgg16 import VGG16
from keras.applications.nasnet import NASNetMobile
from keras.applications.mobilenet_v2 import MobileNetV2
base_model = MobileNetV2(weights='imagenet', include_top=False,input_shape=(dim,dim,3))

# add a global spatial average pooling layer
x = base_model.output
x = GlobalAveragePooling2D()(x)
#x = Flatten()(x)
# let's add a fully-connected layer
x= Dropout(0.25)(x)
x = Dense(100, activation='relu')(x)
x= Dropout(0.25)(x)
#x = Dense(2, activation='softmax')
# and a logistic layer -- let's say we have 200 classes
predictions = Dense(1, activation='sigmoid')(x)


model = Model(inputs=base_model.input, outputs=predictions)

for i, layer in enumerate(base_model.layers):
   print(i, layer.name)


print(len(model.layers))
for layer in model.layers:
   layer.trainable = True


# we need to recompile the model for these modifications to take effect
# we use SGD with a low learning rate
from keras.optimizers import SGD
model.compile(optimizer='Adam', loss='binary_crossentropy',metrics=['accuracy'])
model.summary()
def getModels(dimension,channel):
  model = Sequential()
  model.add(Conv2D(32, kernel_size=(3, 3),
                   activation='relu',
                   input_shape=(dimension,dimension,channel)))
  model.add(Conv2D(64, (3, 3), activation='relu'))
  model.add(MaxPooling2D(pool_size=(2, 2)))
  model.add(Dropout(0.25))
  model.add(GlobalAveragePooling2D())
  model.add(Dense(128, activation='relu'))
  model.add(Dropout(0.5))
  model.add(Dense(1, activation='softmax'))

  model.compile(loss='binary_crossentropy',
                optimizer='adam',
                metrics=['accuracy'])
  return model
def getModels_2(dimension,channel):
  model = Sequential()
  model.add(Conv2D(32, kernel_size=(3, 3),
                   activation='relu',
                   input_shape=(dimension,dimension,channel)))
  model.add(Conv2D(64, (3, 3), activation='relu'))
  model.add(MaxPooling2D(pool_size=(2, 2)))
  model.add(Dropout(0.25))
  model.add(Conv2D(128, (3, 3), activation='relu'))
  model.add(MaxPooling2D(pool_size=(2, 2)))
  model.add(Dropout(0.25))
  model.add(GlobalAveragePooling2D())
  model.add(Dense(128, activation='relu'))
  model.add(Dropout(0.5))
  model.add(Dense(1, activation='softmax'))

  model.compile(loss='binary_crossentropy',
                optimizer='adam',
                metrics=['accuracy'])
  return model
  import numpy as np
from keras.utils import np_utils

indices=list(range(len(Images)))
np.random.seed(23)
np.random.shuffle(indices)
Images = np.array(Images)
Images= Images/255.0
labels = np.array(labels)
#labels=np_utils.to_categorical(labels)
ind=int(len(indices)*0.60)
ind2 = int( len(indices)*0.20)
# train data
X_train=Images[indices[:ind]] 
y_train=labels[indices[:ind]]
# validation data
X_val=Images[indices[ind:ind+ind2]] 
y_val=labels[indices[ind:ind+ind2]]

x_test = Images[indices[ind+ind2:]]
y_test=labels[indices[ind+ind2:]]
print(X_train[0].shape)
#model = getModels(200,3)
from keras.callbacks import ModelCheckpoint
path_model='model_simple_keras_starter.h5' # save model at this location after each epoch
checkpointer = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)
model.fit(x=X_train, y=y_train,
            epochs=40, 
            verbose=1, 
            validation_data=(X_val,y_val),
            shuffle=True,
          callbacks=[
                checkpointer,
            ]
            
            )
print(model.evaluate(x_test,y_test))
  
